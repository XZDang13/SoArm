{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40118e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import mujoco.viewer\n",
    "import mujoco\n",
    "import numpy as np\n",
    "import torch\n",
    "from model.actor_critic import EncoderNet, StochasticDDPGActor\n",
    "from RLAlg.nn.steps import DeterministicContinuousPolicyStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e74af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mujoco.MjModel.from_xml_path(\"env/assets/so101/scene.xml\")\n",
    "d = mujoco.MjData(m)\n",
    "m.opt.timestep = 1/30\n",
    "\n",
    "goal_state = np.array([0.25, 0.0, 0.17, 1.0, 0.0, 0.0, 0.0, 0.7071, 0.7071, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66aab839",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pos = d.qpos[:].copy()\n",
    "current_pos = d.qpos[:].copy()\n",
    "pre_action = np.array([0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cadfa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StochasticDDPGActor(\n",
       "  (layers): Sequential(\n",
       "    (0): MLPLayer(\n",
       "      (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (activate_func): SiLU()\n",
       "    )\n",
       "    (1): MLPLayer(\n",
       "      (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (activate_func): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (policy_layer): DeterministicHead(\n",
       "    (linear): Linear(in_features=256, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "encoder = EncoderNet(6+6+6+3+4+4, [256, 256, 256]).to(device)\n",
    "actor = StochasticDDPGActor(encoder.dim, [256, 256], 6).to(device)\n",
    "\n",
    "encoder_params, actor_params, _ = torch.load(\"model.pth\")\n",
    "encoder.load_state_dict(encoder_params)\n",
    "actor.load_state_dict(actor_params)\n",
    "\n",
    "encoder.eval()\n",
    "actor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "921d1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_action(obs):\n",
    "    obs = torch.from_numpy(obs).unsqueeze(0).float().to(device)\n",
    "\n",
    "    feature = encoder(obs)\n",
    "    step:DeterministicContinuousPolicyStep = actor(feature, std=1.0)\n",
    "    action = step.mean.squeeze(0).cpu().numpy()\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9d4265",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m time_until_next_step = m.opt.timestep - (time.time() - step_start)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m time_until_next_step > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_until_next_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "with mujoco.viewer.launch_passive(m, d) as viewer:\n",
    "    # Close the viewer automatically after simulation_duration wall-seconds.\n",
    "    start = time.time()\n",
    "    while viewer.is_running() and time.time() - start < 50:\n",
    "        step_start = time.time()\n",
    "\n",
    "        obs = np.concatenate([goal_state, current_pos, pre_pos, pre_action])\n",
    "        action = get_action(obs)\n",
    "        target_pos = current_pos + action * 0.25\n",
    "\n",
    "        #target_pos = target_pos.clip(m.jnt_range[:, 0], m.jnt_range[:, 1])\n",
    "\n",
    "        d.qpos[:] = target_pos\n",
    "        # mj_step can be replaced with code that also evaluates\n",
    "        # a policy and applies a control signal before stepping the physics.\n",
    "        mujoco.mj_step(m, d)\n",
    "\n",
    "        pre_pos = current_pos.copy()\n",
    "        current_pos = d.qpos[:].copy()\n",
    "\n",
    "        viewer.sync()\n",
    "\n",
    "        # Rudimentary time keeping, will drift relative to wall clock.\n",
    "        time_until_next_step = m.opt.timestep - (time.time() - step_start)\n",
    "        if time_until_next_step > 0:\n",
    "            time.sleep(time_until_next_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bfe11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isaaclab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
